{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "AWS_KEY                = None\n",
    "AWS_SECRET             = None\n",
    "AWS_REGION             = None\n",
    "\n",
    "# Cluster configuration\n",
    "DWH_CLUSTER_TYPE       = None\n",
    "DWH_NUM_NODES          = None\n",
    "DWH_NODE_TYPE          = None\n",
    "\n",
    "# Redshift details\n",
    "DWH_CLUSTER_IDENTIFIER = None\n",
    "DWH_DB                 = None\n",
    "DWH_DB_USER            = None\n",
    "DWH_DB_PASSWORD        = None\n",
    "DWH_PORT               = None\n",
    "\n",
    "# IAM role\n",
    "DWH_IAM_ROLE_NAME      = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please give your secret key ········································\n"
     ]
    }
   ],
   "source": [
    "AWS_SECRET = getpass.getpass(\"Please give your secret key\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Parse config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "with open('/home/workspace/dev/dwh.cfg') as fp:\n",
    "    config.read_file(fp)\n",
    "    AWS_KEY                = config.get('AWS','KEY')\n",
    "#     AWS_SECRET             = config.get('AWS','SECRET')\n",
    "    AWS_REGION             = config.get('AWS','REGION')\n",
    "    DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "    DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "    DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "    DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "    DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "    DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "    DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "    DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "    DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Read from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "aws_s3 = boto3.resource(\n",
    "    's3',\n",
    "    region_name=AWS_REGION,\n",
    "    aws_access_key_id=AWS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "aws_bucket = aws_s3.Bucket('udacity-dend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "aws_bucket.download_file('log_json_path.json', 'bucket_data/log_json_path.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "aws_bucket.download_file('song_data/A/B/C/TRABCEI128F424C983.json', 'bucket_data/TRABCEI128F424C983.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Lets download a few random files to examine their schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file TRAAAAV128F421A322.json\n",
      "Downloading file TRAAAED128E0783FAB.json\n",
      "Downloading file TRAAAHD128F42635A5.json\n",
      "Downloading file TRAAANK128F428B515.json\n",
      "Downloading file TRAAAPK128E0786D96.json\n",
      "Downloading file TRAAAUC128F428716F.json\n",
      "Downloading file TRAAAYL128F4271A5B.json\n",
      "Downloading file TRAABEV12903CC53A4.json\n",
      "Downloading file TRAABHB12903CAFC2F.json\n",
      "Downloading file TRAABHO12903D08576.json\n"
     ]
    }
   ],
   "source": [
    "total_files = 0\n",
    "\n",
    "for s3_object in aws_bucket.objects.all():\n",
    "    path, filename = os.path.split(s3_object.key)\n",
    "    \n",
    "    if path.startswith(\"song-data/\"):\n",
    "        if total_files < 10:\n",
    "            if rng.rand() >= 0.75:\n",
    "                print(f\"Downloading file {filename}\")\n",
    "                \n",
    "                output_filename = f\"bucket_data/{filename}\"\n",
    "                aws_bucket.download_file(s3_object.key, output_filename)\n",
    "\n",
    "                total_files += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file 2018-11-01-events.json\n",
      "Downloading file 2018-11-08-events.json\n",
      "Downloading file 2018-11-11-events.json\n",
      "Downloading file 2018-11-15-events.json\n",
      "Downloading file 2018-11-18-events.json\n",
      "Downloading file 2018-11-20-events.json\n",
      "Downloading file 2018-11-22-events.json\n"
     ]
    }
   ],
   "source": [
    "total_files = 0\n",
    "\n",
    "for s3_object in aws_bucket.objects.all():\n",
    "    path, filename = os.path.split(s3_object.key)\n",
    "    \n",
    "    if path.startswith(\"log-data/\"):\n",
    "        if total_files < 10:\n",
    "            if rng.rand() >= 0.75:\n",
    "                print(f\"Downloading file {filename}\")\n",
    "                \n",
    "                output_filename = f\"bucket_data/{filename}\"\n",
    "                aws_bucket.download_file(s3_object.key, output_filename)\n",
    "\n",
    "                total_files += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
